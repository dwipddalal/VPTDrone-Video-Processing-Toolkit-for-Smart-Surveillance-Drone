{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries and Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from learner import Learner\n",
    "from loss import *\n",
    "from dataset import *\n",
    "import os\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "normal_train_dataset = Normal_Loader(is_train=1) # this is like a big container that has 810 videos in numpy array format, each of which has 32 segments. And each of this 32 segment is a image of 2048x2048\n",
    "normal_test_dataset = Normal_Loader(is_train=0)\n",
    "# print(Normal_Loader(is_train=1).data_list) # this contains listttssss ye babe ye you got this \n",
    "anomaly_train_dataset = Anomaly_Loader(is_train=1)\n",
    "# print(len(anomaly_train_dataset))\n",
    "anomaly_test_dataset = Anomaly_Loader(is_train=0)\n",
    "# print(len(anomaly_test_dataset))\n",
    "# print(normal_train_dataset)\n",
    "normal_train_loader = DataLoader(normal_train_dataset, batch_size=30, shuffle=True)\n",
    "\n",
    "normal_test_loader = DataLoader(normal_test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "anomaly_train_loader = DataLoader(anomaly_train_dataset, batch_size=30, shuffle=True) \n",
    "anomaly_test_loader = DataLoader(anomaly_test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_test_video = []\n",
    "path = '/home/dwip.dalal/shoplifting/Anomaly-Videos-Part-4/'\n",
    "#path='/home/dwip.dalal/shoplifting_implementation_1/Real-world-Anomaly-Detection-in-Surveillance-Videos-pytorch/DATA/UCF-Crime/'\n",
    "for i in anomaly_test_dataset.data_list:\n",
    "    list_of_test_video.append(path+i.split('|')[0])\n",
    "print(list_of_test_video[40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_test_video[39]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm to check number of frames in a video\n",
    "Just to test for the difference in the number of frames in the video and the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture(list_of_test_video[45])\n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Learner(input_dim=2048, drop_p=0.0).to(device)\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr= 0.001, weight_decay=0.0010000000474974513)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[25, 50])\n",
    "criterion = MIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (normal_inputs, anomaly_inputs) in enumerate(zip(normal_train_loader, anomaly_train_loader)):\n",
    "        inputs = torch.cat([anomaly_inputs, normal_inputs], dim=1)\n",
    "        batch_size = inputs.shape[0]\n",
    "        inputs = inputs.view(-1, inputs.size(-1)).to(device)\n",
    "        outputs = model(inputs)\n",
    "        # print(outputs.shape)\n",
    "        loss = criterion(outputs, batch_size)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    print('loss = {}', train_loss/len(normal_train_loader))\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_abnormal(epoch):\n",
    "    model.eval()\n",
    "    auc = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, data2) in enumerate(zip(anomaly_test_loader, normal_test_loader)): # this make 140 iterations i.e. for 140 videos\n",
    "            inputs, gts, frames = data \n",
    "            inputs = inputs.view(-1, inputs.size(-1)).to(torch.device('cuda'))\n",
    "            # print(frames)\n",
    "            score = model(inputs)\n",
    "            # Score holds value corresponding each of the 32 segments of each video\n",
    "            # MIL is calculated for each of the 32 segments of each video\n",
    "            # so we shall need the score for each of the 32 segments of each video\n",
    "            # this socre for 32 segemetns tells us the probabliy of anomaly happening in each of the 32 segments\n",
    "            score = score.cpu().detach().numpy() \n",
    "            # print(score)\n",
    "            score_list = np.zeros(frames[0]) # score_list will holds score corresponding to each of the frame in the entire video.\n",
    "            \n",
    "            step = np.round(np.linspace(0, frames[0]//16, 33))\n",
    "            # print(step)\n",
    "            # we have already computed C3D features for the whole video and divided the video features into 32 segments.\n",
    "\n",
    "            for j in range(32): # 32 segment frames for one testing video\n",
    "                score_list[int(step[j])*16:(int(step[j+1]))*16] = score[j]\n",
    "            \n",
    "           \n",
    "            gt_list = np.zeros(frames[0]) # gt_list will hold the true value for each of frame in the video segement.\n",
    "            for k in range(len(gts)//2):\n",
    "                s = gts[k*2] # gts is the start and end of frames in which the anomaly will occur. \n",
    "                e = min(gts[k*2+1], frames)\n",
    "                gt_list[s-1:e] = 1\n",
    "\n",
    "            inputs2, gts2, frames2 = data2\n",
    "            inputs2 = inputs2.view(-1, inputs2.size(-1)).to(torch.device('cuda'))\n",
    "            score2 = model(inputs2)\n",
    "            score2 = score2.cpu().detach().numpy()\n",
    "            score_list2 = np.zeros(frames2[0])\n",
    "            step2 = np.round(np.linspace(0, frames2[0]//16, 33))\n",
    "            for kk in range(32):\n",
    "                score_list2[int(step2[kk])*16:(int(step2[kk+1]))*16] = score2[kk]\n",
    "            gt_list2 = np.zeros(frames2[0])\n",
    "            score_list3 = np.concatenate((score_list, score_list2), axis=0)\n",
    "            gt_list3 = np.concatenate((gt_list, gt_list2), axis=0)\n",
    "            # print('this is gt_list', gt_list)\n",
    "            # print('this is score_list3', score_list3) # this is the predicited binary score 1 for anomaly 0 for normal\n",
    "            # so after looking at this two questions remain:\n",
    "            # 1. what is the length of score_list3?\n",
    "            # 2. what does 1 and 0 in it indicate?\n",
    "            # print(len(gt_list3))\n",
    "            fpr, tpr, thresholds = metrics.roc_curve(gt_list3, score_list3, pos_label=1)\n",
    "            # print(fpr, tpr)\n",
    "            if metrics.auc(fpr, tpr) != 'nan':\n",
    "                auc += metrics.auc(fpr, tpr)\n",
    "                \n",
    "        print('auc is', auc/140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0, 300):\n",
    "    train(epoch)\n",
    "    print(test_abnormal(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "def fxn():\n",
    "    print(test_abnormal(epoch))\n",
    "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = pickle.load(open('moodelll.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sass = [0]\n",
    "with torch.no_grad():\n",
    "        for i, (data, data2) in enumerate(zip(anomaly_test_loader, normal_test_loader)): # this make 140 iterations i.e. for 140 videos\n",
    "                inputs, gts, frames = data \n",
    "                inputs = inputs.view(-1, inputs.size(-1)).to(torch.device('cuda'))\n",
    "                # print(frames)\n",
    "                score = model(inputs)\n",
    "                # Score holds value corresponding each of the 32 segments of each video\n",
    "                # MIL is calculated for each of the 32 segments of each video\n",
    "                # so we shall need the score for each of the 32 segments of each video\n",
    "                # this socre for 32 segemetns tells us the probabliy of anomaly happening in each of the 32 segments\n",
    "                score = score.cpu().detach().numpy() \n",
    "                # print(score)\n",
    "                score_list = np.zeros(frames[0]) # score_list will holds score corresponding to each of the frame in the entire video.\n",
    "                \n",
    "                step = np.round(np.linspace(0, frames[0]//16, 33))\n",
    "                # print(step)\n",
    "                # we have already computed C3D features for the whole video and divided the video features into 32 segments.\n",
    "\n",
    "                for j in range(32): # 32 segment frames for one testing video\n",
    "                    score_list[int(step[j])*16:(int(step[j+1]))*16] = score[j]\n",
    "                if len(score_list) == 2804 or len(score_list) == 2803:\n",
    "                    sass = score_list\n",
    "for i in sass:\n",
    "    print(i, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 35\n",
    "list_of_test_video[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to see how is the performance of the model\n",
    "a = 0\n",
    "for i in sass:\n",
    "    a = a + 1 \n",
    "    if i>0.06:\n",
    "        print(a, end=' ')\n",
    "        \n",
    "print(len(sass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd shoplifitng_implementation_1/\n",
    "# %rm test_video_with_text\n",
    "\n",
    "%mkdir test_video_with_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(model, open('moodelll.pkl', 'wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_text(img, text,\n",
    "          font=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "          pos=(0, 0),\n",
    "          font_scale=1,\n",
    "          font_thickness=1,\n",
    "          text_color=(0, 0, 255),\n",
    "          text_color_bg=(0, 0, 0)\n",
    "          ):\n",
    "\n",
    "    x, y = pos\n",
    "    text_size, _ = cv2.getTextSize(text, font, font_scale, font_thickness)\n",
    "    text_w, text_h = text_size\n",
    "    cv2.rectangle(img, pos, (x + text_w, y + text_h), text_color_bg, -1)\n",
    "    cv2.putText(img, text, (x, y + text_h + font_scale - 1), font, font_scale, text_color, font_thickness)\n",
    "\n",
    "    return text_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to write\n",
    "# text on video\n",
    "import cv2\n",
    "cap = cv2.VideoCapture(list_of_test_video[b])\n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "a = 0\n",
    "\n",
    "while(a<length):\n",
    "    a = a + 1\n",
    "    print(a)\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "    if sass[a-1]>0.05: \n",
    "        draw_text(frame, \"shoplifting\", pos=(155, 30))\n",
    "        # draw_text(frame, \"shoplifting\", font_scale=4, pos=(150, 50 + h), text_color_bg=(0, 0, 0))\n",
    "        # cv2.putText(frame,'shoplifting',(155, 50),font, 1,(0, 0, 255),1,cv2.LINE_4)\n",
    "    else:\n",
    "        draw_text(frame, \"normal\", pos=(185, 30), text_color=(255, 255, 255))\n",
    "        # cv2.putText(frame,'normal',(200, 50),font, 1,(255, 255, 255),2,cv2.LINE_4)\n",
    "\n",
    "    path_save = '/home/dwip.dalal/shoplifting_implementation_1/Real-world-Anomaly-Detection-in-Surveillance-Videos-pytorch/test_video_with_text/' + str(a) + '.jpg'\n",
    "    cv2.imwrite(path_save, frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "image_folder = '/home/dwip.dalal/shoplifting_implementation_1/Real-world-Anomaly-Detection-in-Surveillance-Videos-pytorch/test_video_with_text/'\n",
    "video_name = '/home/dwip.dalal/shoplifting_implementation_1/Real-world-Anomaly-Detection-in-Surveillance-Videos-pytorch/video5.avi'\n",
    "\n",
    "images = [int(img[:-4]) for img in os.listdir(image_folder)]\n",
    "images = sorted(images)\n",
    "images = [str(img) + '.jpg' for img in images]\n",
    "print(images)\n",
    "frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "height, width, layers = frame.shape\n",
    "\n",
    "video = cv2.VideoWriter(video_name, 0, 30, (width,height))\n",
    "\n",
    "for image in images:\n",
    "    video.write(cv2.imread(os.path.join(image_folder, image)))\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "video.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pal': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10) \n[GCC 10.3.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "99bd79105e31133f60409838afb54ed31553801c2675cfb9257695e9fe28666d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
